# params.yaml

paths:
  llm_pretrained_path: "Sheared-LLaMa-1.3B"
  embedding_model_path: "opt-1.3b"
  slm_pretrained_path: "gpt2"
  slm_data_path: "train.json"  # should be absolute path

pipeline:
  guest: '9999'  # Replace this party id with actual guest party id in your environment
  arbiter: '9999'  # Replace this party id with actual arbiter party id in your environment
  namespace: 'experiment'
  name: 'slm_train'
  engine_run:
    cores: 1

training:
  use_cpu: false
  num_train_epochs: 1
  per_device_train_batch_size: 2
  slm_generation_batch_size: 32
  seq_num_for_single_category: 200
  slm_generation_config:
    max_new_tokens: 256
    do_sample: true
    temperature: 1.0
    top_k: 50
    top_p: 0.9
    repetition_penalty: 1.0
    pad_token_id: 50256

dataset:
  module_name: 'flex_dataset'
  item_name: 'FlexDataset'
  tokenizer_name_or_path: "gpt2"
  need_preprocess: true
  dataset_name: "yelp_review"
  data_part: "train"
  load_from: "json"
  select_num: 2000
  few_shot_num_per_label: 1

data_collator:
  module_name: 'data_collator.cust_data_collator'
  item_name: 'get_seq2seq_data_collator'
  tokenizer_name_or_path: "gpt2"
  label_pad_token_id: 50256
  pad_token_id: 50256
